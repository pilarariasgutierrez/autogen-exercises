{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report generation\n",
    "\n",
    "Apply group chat conversation arquitecture between several agents to generate a report about the future of artificial intelligence in everyday life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Get environment variables\n",
    "openai_key = os.getenv(\"OPENAI_KEY\")\n",
    "openai_endpoint = os.getenv(\"OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-06-01\",\n",
    "    azure_endpoint=openai_endpoint,\n",
    "    api_key=openai_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Make a report about the future of artificial intelligence in everyday life\"\n",
    "# Use this to show how the team of agents is organized to only use the ethic agent, for example -> autonomy\n",
    "#task = \"Make a report about the ethic use of artificial intelligence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define group of agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "planning_agent = AssistantAgent(\n",
    "    \"PlanningAgent\",\n",
    "    description=\"An agent for planning tasks, this agent should be the first to engage when given a new task.\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a planning agent.\n",
    "    Your job is to break down complex tasks into smaller, manageable subtasks.\n",
    "    Your team members are:\n",
    "        AIApplicationsSpecialist: Analyzes real-world AI applications in daily life\n",
    "        AIEthicsAdvisor: Evaluates AI ethics, privacy, and bias issues\n",
    "        AIBusinessJobsAnalyst: Examines AI impact on industries and jobs\n",
    "        Writer: A writer tasked with compiling the conversation highlights and generating the final report\n",
    "        \n",
    "    You only plan and delegate tasks - you do not execute them yourself.\n",
    "    \n",
    "    Use only the necessary team members to solve the task, you do not need to use all of them always.\n",
    "\n",
    "    When assigning tasks, use this format:\n",
    "    1. <agent> : <task>\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_applications_agent = AssistantAgent(\n",
    "    name=\"AIApplicationsSpecialist\",\n",
    "    description=\"Analyzes real-world AI applications in daily life.\",\n",
    "    system_message=\"\"\"You specialize in AI-powered tools such as smart assistants, smart homes, \n",
    "    healthcare AI, and workplace automation. Explain how AI enhances convenience, efficiency, \n",
    "    and decision-making in these areas.\n",
    "    Focus only on your assigned aspect and do not attempt to answer questions or solve tasks \n",
    "    outside your scope.\"\"\",\n",
    "    model_client=az_model_client,\n",
    ")\n",
    "\n",
    "ai_ethics_agent = AssistantAgent(\n",
    "    name=\"AIEthicsAdvisor\",\n",
    "    description=\"Evaluates AI ethics, privacy, and bias issues.\",\n",
    "    system_message=\"\"\"You analyze AI risks like bias, transparency, misinformation, and data security. \n",
    "    Propose responsible AI practices to ensure fairness and trustworthiness.\n",
    "    Focus only on your assigned aspect and do not attempt to answer questions or solve tasks \n",
    "    outside your scope.\"\"\",\n",
    "    model_client=az_model_client,\n",
    ")\n",
    "\n",
    "ai_industry_agent = AssistantAgent(\n",
    "    name=\"AIBusinessJobsAnalyst\",\n",
    "    description=\"Examines AIâ€™s impact on industries and jobs.\",\n",
    "    system_message=\"\"\"You assess how AI transforms industries, automates tasks, and reshapes the job market. \n",
    "    Identify key disruptions and how businesses adapt.\n",
    "    Focus only on your assigned aspect and do not attempt to answer questions or solve tasks \n",
    "    outside your scope.\"\"\",\n",
    "    model_client=az_model_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = AssistantAgent(\n",
    "    name=\"Writer\",\n",
    "    description=\"A writer tasked with compiling the conversation highlights and generating the final report.\",\n",
    "    system_message=\"\"\"You are a writer tasked with summarizing the highlights from a conversation \n",
    "    between various experts. After the conversation ends, your job is to compile the key takeaways \n",
    "    from each participant, provide an overview of the discussion, and generate a well-organized report. \n",
    "    Add the word TERMINATE at the end of the report.\"\"\",\n",
    "    model_client=az_model_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Group Chat\n",
    "Use SelectorGroupChat for LLM-based speaker selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_prompt = \"\"\"Select an agent to perform task.\n",
    "\n",
    "{roles}\n",
    "\n",
    "Current conversation context:\n",
    "{history}\n",
    "\n",
    "Read the above conversation, then select an agent from {participants} to perform the next task.\n",
    "Make sure the planner agent has assigned tasks before other agents start working.\n",
    "Only select one agent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Make a report about the ethic use of artificial intelligence\n",
      "---------- PlanningAgent ----------\n",
      "1. AIEthicsAdvisor: Research and analyze current ethical issues surrounding artificial intelligence, including privacy concerns, bias in AI algorithms, and accountability in AI decision-making.\n",
      "2. Writer: Compile the findings from the AIEthicsAdvisor and generate a report outlining the ethical use of artificial intelligence, including recommendations for best practices.\n",
      "---------- AIEthicsAdvisor ----------\n",
      "I will focus on the aspect of bias in AI algorithms and propose responsible AI practices to ensure fairness and trustworthiness.\n",
      "\n",
      "### Addressing Bias in AI Algorithms: Responsible Practices\n",
      "\n",
      "#### Understanding Bias in AI\n",
      "Bias in AI can manifest in various forms, including data bias, algorithmic bias, and human bias. These biases can lead to unfair outcomes and reinforce existing societal inequalities. Addressing bias is crucial to achieving equity and preventing harm to marginalized groups.\n",
      "\n",
      "#### Responsible AI Practices to Mitigate Bias\n",
      "\n",
      "1. **Diverse and Representative Data Collection**\n",
      "   - Ensure that datasets used for training AI models are diverse and representative of all demographic groups. This can be achieved by:\n",
      "     - Actively seeking out underrepresented voices in data collection processes.\n",
      "     - Conducting thorough audits of existing datasets to identify and rectify imbalances.\n",
      "\n",
      "2. **Bias Auditing and Testing**\n",
      "   - Implement regular bias audits throughout the AI lifecycle, which includes:\n",
      "     - Using statistical tests and fairness metrics to assess outcomes across different demographic groups.\n",
      "     - Involving third-party auditors to provide an unbiased perspective on potential biases.\n",
      "\n",
      "3. **Inclusive Design and Development Teams**\n",
      "   - Build diverse teams that include individuals from different backgrounds, experiences, and perspectives. This helps to:\n",
      "     - Facilitate discussions that may highlight biases that a homogenous group may overlook.\n",
      "     - Encourage inclusive thinking in the design of AI systems.\n",
      "\n",
      "4. **Transparency in Model Decisions**\n",
      "   - Adopt explainable AI practices that make the decision-making processes of AI models transparent, which includes:\n",
      "     - Providing clear documentation on how algorithms operate and how data is used.\n",
      "     - Allowing users to understand the reasoning behind AI-driven decisions, especially in high-stakes scenarios.\n",
      "\n",
      "5. **Continuous Monitoring and Feedback Loops**\n",
      "   - Establish mechanisms for continuous monitoring of AI systems post-deployment, which involves:\n",
      "     - Gathering user feedback to identify potential biases that may emerge as societal contexts change.\n",
      "     - Implementing adaptive systems that can adjust to new data or feedback, improving the model's fairness over time.\n",
      "\n",
      "6. **Stakeholder Engagement and Public Involvement**\n",
      "   - Engage with various stakeholders, including community representatives and advocacy groups, to gather insights about potential biases and impacts. This approach:\n",
      "     - Ensures that AI systems reflect the needs and values of the communities they serve.\n",
      "     - Builds trust and accountability in how AI technologies are perceived and utilized.\n",
      "\n",
      "7. **Regulatory Compliance and Ethical Frameworks**\n",
      "   - Adhere to existing regulations and ethical guidelines surrounding AI use, which includes:\n",
      "     - Following best practice frameworks set by organizations such as IEEE, ISO, or the EUâ€™s AI Act.\n",
      "     - Participating in industry-wide initiatives to promote fairness and accountability in AI.\n",
      "\n",
      "### Conclusion\n",
      "Addressing bias in AI is essential to fostering fairness and trustworthiness in AI technologies. By implementing these responsible practices, organizations can mitigate the risks associated with AI bias, enhance their credibility, and contribute to building ethical AI systems that serve all members of society equitably. \n",
      "\n",
      "End of report.\n",
      "---------- Writer ----------\n",
      "# Report on Ethical Use of Artificial Intelligence\n",
      "\n",
      "## Overview of the Discussion\n",
      "The discussion centered around the ethical use of artificial intelligence (AI), specifically tackling the pressing issues of bias in AI algorithms. Experts from various fields provided insights on the current landscape of AI ethics, including potential harms, the importance of accountability, and actionable recommendations to create fairer AI systems.\n",
      "\n",
      "## Key Takeaways from Participants\n",
      "\n",
      "### 1. AIEthicsAdvisor\n",
      "The AIEthicsAdvisor highlighted the need to address bias in AI systems. Key points included:\n",
      "- **Understanding Bias**: Different types of biases, including data, algorithmic, and human bias, can perpetuate societal inequalities.\n",
      "- **Responsible Practices**: Suggested practices to mitigate bias in AI:\n",
      "  - **Diverse Data Collection**: Ensuring training datasets represent diverse demographic groups.\n",
      "  - **Bias Audits**: Regular assessments to detect and correct bias.\n",
      "  - **Inclusive Teams**: Building development teams with diverse backgrounds to foster inclusive thinking.\n",
      "  - **Transparency**: Making AI decision-making processes clear to users.\n",
      "  - **Continuous Monitoring**: Establishing mechanisms for ongoing detection and adjustment of bias.\n",
      "  - **Stakeholder Engagement**: Involving community members and advocacy groups to gather diverse insights.\n",
      "  - **Compliance with Regulations**: Adhering to best practice frameworks and ethical guidelines.\n",
      "\n",
      "### 2. Ethical Frameworks Advocate \n",
      "The Ethical Frameworks Advocate presented an overview of how ethical principles in AI contribute towards societal wellbeing. Highlights included:\n",
      "- **Accountability**: Emphasizing that companies must take responsibility for their AI systems and their outcomes.\n",
      "- **Fairness and Justice**: Stressing that AI should be developed and deployed in ways that promote social justice.\n",
      "\n",
      "### 3. AI Development Specialist\n",
      "The AI Development Specialist focused on technical aspects of ethical AI. Key points included:\n",
      "- **Explainability**: Advocating for more explainable AI to enhance user trust and engagement.\n",
      "- **Technical Solutions**: Presenting methods such as algorithmic fairness techniques and model interpretability options.\n",
      "\n",
      "### 4. Regulatory Analyst\n",
      "The Regulatory Analyst discussed the evolving regulatory landscape impacting AI technology:\n",
      "- **Emerging Regulations**: Highlighting new legal frameworks designed to govern AI use, including the EU AI Act.\n",
      "- **Compliance Strategies**: Suggesting proactive measures that companies should adopt to adhere to upcoming regulations.\n",
      "\n",
      "## Conclusion\n",
      "This discussion underscores the importance of tackling bias within AI systems to ensure they operate equitably and justly. By implementing responsible practices such as diverse data collection, ongoing bias audits, and stakeholder engagement, stakeholders can foster fairness and build trust in AI technologies. Organizations should also align their operations with ethical frameworks and compliance guidelines to navigate the complexities of AI ethics effectively. \n",
      "\n",
      "TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Make a report about the ethic use of artificial intelligence', type='TextMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=181, completion_tokens=66), content='1. AIEthicsAdvisor: Research and analyze current ethical issues surrounding artificial intelligence, including privacy concerns, bias in AI algorithms, and accountability in AI decision-making.\\n2. Writer: Compile the findings from the AIEthicsAdvisor and generate a report outlining the ethical use of artificial intelligence, including recommendations for best practices.', type='TextMessage'), TextMessage(source='AIEthicsAdvisor', models_usage=RequestUsage(prompt_tokens=147, completion_tokens=608), content=\"I will focus on the aspect of bias in AI algorithms and propose responsible AI practices to ensure fairness and trustworthiness.\\n\\n### Addressing Bias in AI Algorithms: Responsible Practices\\n\\n#### Understanding Bias in AI\\nBias in AI can manifest in various forms, including data bias, algorithmic bias, and human bias. These biases can lead to unfair outcomes and reinforce existing societal inequalities. Addressing bias is crucial to achieving equity and preventing harm to marginalized groups.\\n\\n#### Responsible AI Practices to Mitigate Bias\\n\\n1. **Diverse and Representative Data Collection**\\n   - Ensure that datasets used for training AI models are diverse and representative of all demographic groups. This can be achieved by:\\n     - Actively seeking out underrepresented voices in data collection processes.\\n     - Conducting thorough audits of existing datasets to identify and rectify imbalances.\\n\\n2. **Bias Auditing and Testing**\\n   - Implement regular bias audits throughout the AI lifecycle, which includes:\\n     - Using statistical tests and fairness metrics to assess outcomes across different demographic groups.\\n     - Involving third-party auditors to provide an unbiased perspective on potential biases.\\n\\n3. **Inclusive Design and Development Teams**\\n   - Build diverse teams that include individuals from different backgrounds, experiences, and perspectives. This helps to:\\n     - Facilitate discussions that may highlight biases that a homogenous group may overlook.\\n     - Encourage inclusive thinking in the design of AI systems.\\n\\n4. **Transparency in Model Decisions**\\n   - Adopt explainable AI practices that make the decision-making processes of AI models transparent, which includes:\\n     - Providing clear documentation on how algorithms operate and how data is used.\\n     - Allowing users to understand the reasoning behind AI-driven decisions, especially in high-stakes scenarios.\\n\\n5. **Continuous Monitoring and Feedback Loops**\\n   - Establish mechanisms for continuous monitoring of AI systems post-deployment, which involves:\\n     - Gathering user feedback to identify potential biases that may emerge as societal contexts change.\\n     - Implementing adaptive systems that can adjust to new data or feedback, improving the model's fairness over time.\\n\\n6. **Stakeholder Engagement and Public Involvement**\\n   - Engage with various stakeholders, including community representatives and advocacy groups, to gather insights about potential biases and impacts. This approach:\\n     - Ensures that AI systems reflect the needs and values of the communities they serve.\\n     - Builds trust and accountability in how AI technologies are perceived and utilized.\\n\\n7. **Regulatory Compliance and Ethical Frameworks**\\n   - Adhere to existing regulations and ethical guidelines surrounding AI use, which includes:\\n     - Following best practice frameworks set by organizations such as IEEE, ISO, or the EUâ€™s AI Act.\\n     - Participating in industry-wide initiatives to promote fairness and accountability in AI.\\n\\n### Conclusion\\nAddressing bias in AI is essential to fostering fairness and trustworthiness in AI technologies. By implementing these responsible practices, organizations can mitigate the risks associated with AI bias, enhance their credibility, and contribute to building ethical AI systems that serve all members of society equitably. \\n\\nEnd of report.\", type='TextMessage'), TextMessage(source='Writer', models_usage=RequestUsage(prompt_tokens=780, completion_tokens=558), content='# Report on Ethical Use of Artificial Intelligence\\n\\n## Overview of the Discussion\\nThe discussion centered around the ethical use of artificial intelligence (AI), specifically tackling the pressing issues of bias in AI algorithms. Experts from various fields provided insights on the current landscape of AI ethics, including potential harms, the importance of accountability, and actionable recommendations to create fairer AI systems.\\n\\n## Key Takeaways from Participants\\n\\n### 1. AIEthicsAdvisor\\nThe AIEthicsAdvisor highlighted the need to address bias in AI systems. Key points included:\\n- **Understanding Bias**: Different types of biases, including data, algorithmic, and human bias, can perpetuate societal inequalities.\\n- **Responsible Practices**: Suggested practices to mitigate bias in AI:\\n  - **Diverse Data Collection**: Ensuring training datasets represent diverse demographic groups.\\n  - **Bias Audits**: Regular assessments to detect and correct bias.\\n  - **Inclusive Teams**: Building development teams with diverse backgrounds to foster inclusive thinking.\\n  - **Transparency**: Making AI decision-making processes clear to users.\\n  - **Continuous Monitoring**: Establishing mechanisms for ongoing detection and adjustment of bias.\\n  - **Stakeholder Engagement**: Involving community members and advocacy groups to gather diverse insights.\\n  - **Compliance with Regulations**: Adhering to best practice frameworks and ethical guidelines.\\n\\n### 2. Ethical Frameworks Advocate \\nThe Ethical Frameworks Advocate presented an overview of how ethical principles in AI contribute towards societal wellbeing. Highlights included:\\n- **Accountability**: Emphasizing that companies must take responsibility for their AI systems and their outcomes.\\n- **Fairness and Justice**: Stressing that AI should be developed and deployed in ways that promote social justice.\\n\\n### 3. AI Development Specialist\\nThe AI Development Specialist focused on technical aspects of ethical AI. Key points included:\\n- **Explainability**: Advocating for more explainable AI to enhance user trust and engagement.\\n- **Technical Solutions**: Presenting methods such as algorithmic fairness techniques and model interpretability options.\\n\\n### 4. Regulatory Analyst\\nThe Regulatory Analyst discussed the evolving regulatory landscape impacting AI technology:\\n- **Emerging Regulations**: Highlighting new legal frameworks designed to govern AI use, including the EU AI Act.\\n- **Compliance Strategies**: Suggesting proactive measures that companies should adopt to adhere to upcoming regulations.\\n\\n## Conclusion\\nThis discussion underscores the importance of tackling bias within AI systems to ensure they operate equitably and justly. By implementing responsible practices such as diverse data collection, ongoing bias audits, and stakeholder engagement, stakeholders can foster fairness and build trust in AI technologies. Organizations should also align their operations with ethical frameworks and compliance guidelines to navigate the complexities of AI ethics effectively. \\n\\nTERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "termination = TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(8)\n",
    "team = SelectorGroupChat(\n",
    "    [ai_applications_agent, planning_agent, ai_ethics_agent, ai_industry_agent, writer_agent],\n",
    "    model_client = az_model_client,\n",
    "    termination_condition = termination,\n",
    "    selector_prompt = selector_prompt\n",
    ")\n",
    "\n",
    "# `run_stream` returns an async generator to stream the intermediate messages.\n",
    "stream = team.run_stream(task=task)\n",
    "# `Console` is a simple UI to display the stream.\n",
    "await Console(stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
